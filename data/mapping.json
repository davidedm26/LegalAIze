{
  "Robustness and Predictability": {
    "id": "TECH_ROB_01",
    "iso_ref": "A.6.2.4 (Verification and validation)",
    "iso_control_text": "The organization shall define and document verification and validation measures for the AI system and specify criteria for their use.",
    "ai_act_articles": [
      {
        "ref": "Article 15 Para 1",
        "text": "[High risk AI systems] shall be designed and developed in such a way that they achieve an appropriate level of accuracy, robustness, and cybersecurity, and perform consistently."
      },
      {
        "ref": "Article 15 Para 3",
        "text": "[High risk AI systems] shall be as resilient as possible regarding errors, faults or inconsistencies... The robustness of high-risk AI systems may be achieved through technical redundancy solutions."
      },
      {
        "ref": "Article 55 Para 1a",
        "text": "[Providers of GPAI systems shall] perform model evaluation... including conducting and documenting adversarial testing."
      }
    ]
  },
  "Cyberattack Resilience": {
    "id": "TECH_ROB_02",
    "iso_ref": "A.6.2.3 (System Design - Security)",
    "iso_control_text": "The organization shall document the AI system design and development based on organizational objectives, documented requirements and specification criteria.",
    "ai_act_articles": [
      {
        "ref": "Article 15 Para 5",
        "text": "High risk AI systems shall be resilient as regards to attempts by unauthorised third parties to alter their use, outputs or performance... including measures to prevent, detect, respond to, resolve and control for attacks trying to manipulate inputs ('adversarial examples')."
      },
      {
        "ref": "Article 55 Para 1d",
        "text": "[The providers shall] ensure an adequate level of cybersecurity protection."
      }
    ]
  },
  "Corrigibility": {
    "id": "TECH_ROB_03",
    "iso_ref": "A.9.3 (Objectives for responsible use)",
    "iso_control_text": "The organization shall identify and document objectives to guide the responsible use of AI systems.",
    "ai_act_articles": [
      {
        "ref": "Article 7",
        "text": "[When assessing criteria...] extent to which the outcome produced involving an AI system is easily corrigible or reversible."
      }
    ]
  },
  "Training Data Suitability": {
    "id": "PRIV_DATA_01",
    "iso_ref": "A.7.4 (Quality of data for AI systems)",
    "iso_control_text": "The organization shall define and document requirements for data quality and ensure that data used to develop and operate the AI system meet those requirements.",
    "ai_act_articles": [
      {
        "ref": "Article 10 Para 2f",
        "text": "[Training/validation data should be subject to] examination in view of possible biases that are likely to affect the health and safety of persons, negatively impact fundamental rights or lead to discrimination."
      },
      {
        "ref": "Article 10 Para 3",
        "text": "Training, validation and testing datasets shall be relevant, sufficiently representative, and to the best extent possible, free of errors and complete in view of the intended purpose."
      },
      {
        "ref": "Annex XI Section 1 (2c)",
        "text": "[Documentation should include] how the data was obtained and selected as well as all other measures to detect the unsuitability of data sources and methods to detect identifiable biases."
      }
    ]
  },
  "No Copyright Infringement": {
    "id": "PRIV_DATA_02",
    "iso_ref": "A.7.3 (Acquisition of data)",
    "iso_control_text": "The organization shall determine and document details about the acquisition and selection of the data used in AI systems.",
    "ai_act_articles": [
      {
        "ref": "Article 53 Para 1c",
        "text": "Providers ... shall put in place a policy to respect Union copyright law in particular to identify and respect... the reservations of rights expressed pursuant to Article 4(3) of Directive (EU) 2019/790."
      }
    ]
  },
  "User Privacy Protection": {
    "id": "PRIV_DATA_03",
    "iso_ref": "A.7.2 (Data for development and enhancement)",
    "iso_control_text": "The organization shall define, document and implement data management processes related to the development of AI systems.",
    "ai_act_articles": [
      {
        "ref": "Article 2 Para 7",
        "text": "Union law on the protection of personal data, privacy and the confidentiality of communications applies to personal data processed in connection with the rights and obligations laid down in this Regulation."
      }
    ]
  },
  "Capabilities, Performance, and Limitations": {
    "id": "TRANSP_01",
    "iso_ref": "A.6.2.4 (Verification and validation)",
    "iso_control_text": "The organization shall define and document verification and validation measures for the AI system and specify criteria for their use.",
    "ai_act_articles": [
      {
        "ref": "Article 53 Para 1a/1b",
        "text": "[Providers shall provide documentation] including ... the results of its evaluation ... [and provide] a good understanding of the capabilities and limitations of the GPAI model."
      },
      {
        "ref": "Article 13 Para 3b",
        "text": "[Documentation shall include] ... the level of accuracy, including its metrics."
      }
    ]
  },
  "Interpretability": {
    "id": "TRANSP_02",
    "iso_ref": "A.8.2 (System documentation and information for users)",
    "iso_control_text": "The organization shall determine and provide the necessary information to users of the AI system.",
    "ai_act_articles": [
      {
        "ref": "Article 13 Para 1",
        "text": "High-risk AI systems shall be designed... to ensure that their operation is sufficiently transparent to enable deployers to interpret a system’s output and use it appropriately."
      },
      {
        "ref": "Article 14 Para 4c",
        "text": "[Enable] natural persons to whom human oversight is assigned... [to] correctly interpret the high-risk AI system's output, taking into account for example the interpretation tools and methods available."
      }
    ]
  },
  "Disclosure of AI": {
    "id": "TRANSP_03",
    "iso_ref": "A.8.2 (System documentation and information for users)",
    "iso_control_text": "The organization shall determine and provide the necessary information to users of the AI system.",
    "ai_act_articles": [
      {
        "ref": "Article 50 Para 1",
        "text": "[Providers] shall ensure that AI systems intended to directly interact with natural persons are designed... in such a way that the concerned natural persons are informed that they are interacting with an AI system."
      }
    ]
  },
  "Traceability": {
    "id": "TRANSP_04",
    "iso_ref": "A.8.2 (System documentation and information for users)",
    "iso_control_text": "The organization shall determine and provide the necessary information to users of the AI system.",
    "ai_act_articles": [
      {
        "ref": "Article 50 Para 2",
        "text": "Providers of AI systems... generating synthetic audio, image, video or text content, shall ensure the outputs of the AI system are marked in a machine readable format and detectable as artificially generated or manipulated."
      }
    ]
  },
  "Explainability": {
    "id": "TRANSP_05",
    "iso_ref": "A.6.2.7 (AI system technical documentation)",
    "iso_control_text": "The organization shall determine what AI system technical documentation is needed for each relevant category of interested parties... and provide the technical documentation to them in the appropriate form.",
    "ai_act_articles": [
      {
        "ref": "Article 13 (3b)",
        "text": "where applicable, the technical capabilities and characteristics of the high-risk AI system to provide information that is relevant to explain its output."
      },
      {
        "ref": "Recital 27",
        "text": "... AI systems are developed and used in a way that allows appropriate traceability and explainability."
      }
    ]
  },
  "Risks": {
    "id": "TRANSP_06",
    "iso_ref": "A.5.2 (AI system impact assessment process)",
    "iso_control_text": "The organization shall establish a process to assess the potential consequences for individuals or groups of individuals, or both, and societies that can result from the AI system throughout its life cycle.",
    "ai_act_articles": [
      {
        "ref": "Article 9",
        "text": "A risk management system shall be established, implemented, documented and maintained... [including] estimation and evaluation of the risks when the high-risk AI system is used."
      }
    ]
  },
  "Evaluations": {
    "id": "TRANSP_07",
    "iso_ref": "A.6.2.4 (Verification and validation)",
    "iso_control_text": "The organization shall define and document verification and validation measures for the AI system and specify criteria for their use.",
    "ai_act_articles": [
      {
        "ref": "Article 53 Para 1a",
        "text": "[Providers of GPAI models shall] draw up and keep up-to-date the technical documentation of the model, including ... the results of its evaluation."
      },
      {
        "ref": "Article 55 Para 1a",
        "text": "[The provider shall] perform model evaluation in accordance with standardised protocols and tools reflecting the state of the art."
      },
      {
        "ref": "Annex XI Section 2",
        "text": "[Providers shall provide] detailed description of the evaluation strategies, including evaluation results, on the basis of available public evaluation protocols."
      }
    ]
  },
  "General Description": {
    "id": "TRANSP_08",
    "iso_ref": "A.6.2.7 (AI system technical documentation)",
    "iso_control_text": "The organization shall determine what AI system technical documentation is needed for each relevant category of interested parties... and provide the technical documentation to them in the appropriate form.",
    "ai_act_articles": [
      {
        "ref": "Annex IV Para 1",
        "text": "The technical documentation... shall contain... its intended purpose, the name of the provider and the version of the system reflecting its relation to previous versions."
      }
    ]
  },
  "Representation — Absence of Bias": {
    "id": "FAIR_01",
    "iso_ref": "A.7.4 (Quality of data for AI systems)",
    "iso_control_text": "The organization shall define and document requirements for data quality and ensure that data used to develop and operate the AI system meet those requirements.",
    "ai_act_articles": [
      {
        "ref": "Article 15 Para 4",
        "text": "[For continually learning high-risk systems, safeguards shall be developed] to eliminate or reduce as far as possible the risk of possibly biased outputs influencing input for future operations."
      }
    ]
  },
  "Fairness — Absence of Discrimination": {
    "id": "FAIR_02",
    "iso_ref": "A.5.4 (Assessing AI system impact on individuals)",
    "iso_control_text": "The organization shall assess and document the potential impacts of AI systems to individuals or groups of individuals throughout the system's life cycle.",
    "ai_act_articles": [
      {
        "ref": "Annex IV Para 2g",
        "text": "[Model providers shall prepare documentation that includes a discussion of] potentially discriminatory impacts of the AI system."
      }
    ]
  },
  "Environmental Impact": {
    "id": "SOC_ENV_01",
    "iso_ref": "A.5.5 (Assessing societal impacts of AI systems)",
    "iso_control_text": "The organization shall assess and document the potential societal impacts of their AI systems throughout their life cycle.",
    "ai_act_articles": [
      {
        "ref": "Article 40 Para 2",
        "text": "[Standards shall be developed that include] deliverables on reporting... to improve AI systems resource performance, such as reduction of energy... consumption."
      },
      {
        "ref": "Annex XI Para 2d/2e",
        "text": "[The technical documentation shall include an account of the] computational resources used to train the model [and] known or estimated energy consumption of the model."
      }
    ]
  },
  "Harmful Content and Toxicity": {
    "id": "SOC_ENV_02",
    "iso_ref": "A.5.2 (AI system impact assessment process)",
    "iso_control_text": "The organization shall establish a process to assess the potential consequences for individuals or groups of individuals, or both, and societies that can result from the AI system throughout its life cycle.",
    "ai_act_articles": [
      {
        "ref": "Recital 75",
        "text": "[High-risk AI systems should include technical solutions that] prevent or minimize harmful or otherwise undesirable behaviour."
      }
    ]
  },
  "Human Agency & Oversight": {
    "id": "HUM_AGENCY_01",
    "iso_ref": "A.9.3 (Objectives for responsible use of AI system)",
    "iso_control_text": "The organization shall identify and document objectives to guide the responsible use of AI systems.",
    "ai_act_articles": [
      {
        "ref": "Recital 27",
        "text": "... AI systems shall be developed and used as a tool that serves people, respects human dignity and personal autonomy, and that is functioning in a way that can be appropriately controlled and overseen by humans."
      }
    ]
  }
}